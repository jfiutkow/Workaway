{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaway script - batch countries webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import FALSE\n",
    "import time\n",
    "from operator import contains\n",
    "from select import select\n",
    "from tomlkit import key_value\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##### INPUT AREA #####\n",
    "website = 'https://www.workaway.info/en/hostlist'\n",
    "countries = pd.read_csv(\"Countries.csv\")\n",
    "feedback = 0\n",
    "lastminute = 0\n",
    "##### END OF INPUT AREA #####\n",
    "\n",
    "def configure_driver():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    ### Maximize window\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    ### Add the argument and make the browser Headless.\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    ### Instantiate the Webdriver\n",
    "    driver = webdriver.Chrome(options = chrome_options)\n",
    "    return driver\n",
    "\n",
    "### Extracting function on hostlist page\n",
    "def extract_element(driver, \n",
    "                    my_timer, \n",
    "                    element, \n",
    "                    path, \n",
    "                    extract_attribute = 'text', \n",
    "                    attribute_version = 1, \n",
    "                    attribute_value = \"src\"):\n",
    "    if attribute_version == 0:\n",
    "        try:\n",
    "            match_temp = WebDriverWait(driver, my_timer).until(EC.presence_of_all_elements_located((By.XPATH, path)))\n",
    "            match = len(match_temp)\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: photos not found\")\n",
    "            match = np.nan\n",
    "    elif attribute_version == 3:\n",
    "        match = []\n",
    "        try:\n",
    "            match_temp = WebDriverWait(driver, my_timer).until(EC.presence_of_all_elements_located((By.XPATH, path)))\n",
    "            for match_i in match_temp:\n",
    "                match.append(getattr(match_i, extract_attribute))\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: comments not found\")\n",
    "            match = np.nan\n",
    "    else:\n",
    "        try:\n",
    "            match_temp = WebDriverWait(driver, my_timer).until(EC.presence_of_element_located((By.XPATH, path)))\n",
    "            if attribute_version == 2:\n",
    "                try:\n",
    "                    match = getattr(match_temp, extract_attribute)(attribute_value)\n",
    "                except:\n",
    "                    print(\"New error '2' to handle\")\n",
    "            elif attribute_version == 1:\n",
    "                try:\n",
    "                    match = getattr(match_temp, extract_attribute)\n",
    "                except:\n",
    "                    print(\"New error '1' to handle\")\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: paragraph not found\")\n",
    "            match = np.nan\n",
    "    element.append(match)\n",
    "\n",
    "### Open the Workaway finding host website\n",
    "driver = configure_driver()\n",
    "driver.get(website)\n",
    "\n",
    "### COOKIES ACCEPT\n",
    "cookie_accept = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'CybotCookiebotDialogBodyButtonAccept')))\n",
    "driver.execute_script(\"arguments[0].click();\", cookie_accept)\n",
    "\n",
    "### Check \"only with feedback\" checkbox\n",
    "if feedback == 1 and (driver.find_element(By.ID, 'with_feedback').is_selected()) != True:\n",
    "    driver.find_element(By.ID, 'with_feedback').is_selected()\n",
    "    feedback_checkbox = driver.find_element('xpath', '//label[@for=\"with_feedback\"]/descendant::div')\n",
    "    feedback_checkbox.click()\n",
    "\n",
    "### LOOP THROUUGH COUNTRIES IN THE CSV LIST\n",
    "for country in countries['country']:\n",
    "    ### Input the name of country/region/continent + activate\n",
    "    try:\n",
    "        searchbar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//input[@placeholder=\"Anywhere\"]')))\n",
    "    except TimeoutException:\n",
    "        print(f'INFO: Looks like you broken the site during {country} search')\n",
    "        driver.quit() #this was added to close the previous driver - TO BE TESTED\n",
    "        driver.get(website)\n",
    "        continue\n",
    "    searchbar.click()\n",
    "    time.sleep(2)\n",
    "    ### Alternative clicking type on searchbar\n",
    "    #searchbar = driver.find_element('xpath', '//input[@placeholder=\"Anywhere\"]')\n",
    "    #driver.execute_script(\"arguments[0].click();\", searchbar)\n",
    "    print(f'printing just before sending the command to searchbox {country}')\n",
    "    searchbar.clear()\n",
    "    searchbar.send_keys(country) \n",
    "    time.sleep(2)\n",
    "    searchbar.send_keys(Keys.ARROW_DOWN)\n",
    "    searchbar.send_keys(Keys.ENTER)\n",
    "    ### Handling of optional visa popup - United Kingdom and United States\n",
    "    try:\n",
    "        visabutton = WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, '//button[@data-action=\"visaagree\"]')))\n",
    "        visabutton.click()\n",
    "    except TimeoutException:\n",
    "        print(\"No Visa popup to handle\")    ### Find first host on the Listentry Title object and open it\n",
    "    try:\n",
    "        hostlist = WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"listentry-content\"]/child::a')))\n",
    "    except TimeoutException:\n",
    "        continue\n",
    "    driver.execute_script(\"arguments[0].click();\", hostlist)\n",
    "    #hostlist.click() #optional method if above doesn't work\n",
    "    \n",
    "    ### Handling opened tabs\n",
    "    p = driver.window_handles[0]\n",
    "    ### obtain browser tab window\n",
    "    c = driver.window_handles[1]\n",
    "    driver.switch_to.window(c)\n",
    "    try:\n",
    "        visabutton = WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, '//button[@data-action=\"visaagree\"]')))\n",
    "        visabutton.click()\n",
    "    except TimeoutException:\n",
    "        print(\"No Visa popup to handle\")\n",
    "        \n",
    "    ### WEBSCRAPING THE HOST DATA ###\n",
    "    ### Lists initialization\n",
    "    title = [] #\n",
    "    country_host = [] #\n",
    "    host_rating = [] #\n",
    "    feedback_no = [] #\n",
    "    h_comm = [] #\n",
    "    ww_comm = [] #\n",
    "    last_activity = [] #\n",
    "    reply_rate = [] #\n",
    "    average_reply_time = [] #\n",
    "    favourited = [] #\n",
    "    min_stay = [] #\n",
    "    description = [] #\n",
    "    types_of_help = [] #\n",
    "    cultural_exchange = [] #\n",
    "    help = [] #\n",
    "    languages_spoken = [] #\n",
    "    accommodation = [] #\n",
    "    what_else = [] #\n",
    "    internet_access = [] #\n",
    "    limited_internet = [] #\n",
    "    pets = [] #\n",
    "    smokers = [] #\n",
    "    hosting_families = [] #\n",
    "    digital_nomad = [] #\n",
    "    campervans = [] #\n",
    "    possibly_pets = [] #\n",
    "    workawayer_total = [] #\n",
    "    hours_expected = [] #\n",
    "    number_of_photos = [] #\n",
    "    feedback_accuracy = [] #\n",
    "    feedback_cultural_exchange = [] #\n",
    "    feedback_communication = [] #\n",
    "    ### For LOOP to iterate over number of found hosts\n",
    "    i = 1\n",
    "    while i < 20000:\n",
    "        extract_element(driver, 10, title, '//div[@class=\"details\"]//child::h1', 'text')\n",
    "        extract_element(driver, 1, country_host, '//div[@class=\"country-row\"]//child::p', 'text')\n",
    "        extract_element(driver, 1, host_rating, '//div[contains(@class, \"hr\")]', 'get_attribute', attribute_version = 2, attribute_value = \"class\")\n",
    "        extract_element(driver, 1, feedback_no, '//h2[text()=\"Feedback\"]//parent::div//following-sibling::div[1]//p', 'text')\n",
    "        extract_element(driver, 1, last_activity, '//*[text()=\"Last activity\"]//following::div[1]//child::p', 'text')\n",
    "        extract_element(driver, 1, reply_rate, '//*[text()=\"Reply rate\"]//following::div[1]//child::p', 'text')\n",
    "        extract_element(driver, 1, average_reply_time, '//*[text()=\"Average reply time:\"]//following::div[1]//child::p', 'text')\n",
    "        extract_element(driver, 1, favourited, '//p[@class=\"blue-text\"]', 'text')\n",
    "        extract_element(driver, 1, min_stay, '//p[@class=\"text-muted\"]', 'text')\n",
    "        extract_element(driver, 1, description, '(//div[@id=\"section-information\"]//descendant::p)[1]', 'text')\n",
    "        extract_element(driver, 1, types_of_help, '(//div[@id=\"section-information\"]//descendant::p)[2]', 'text')\n",
    "        extract_element(driver, 1, internet_access, '//*[text()=\"Internet access\"]//parent::div//parent::li//img[contains(@src, \"\")]', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, cultural_exchange, '//img[@alt=\"Cultural exchange and learning opportunities\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, help, '//img[@alt=\"Help\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, languages_spoken, '//h2[contains(text(), \"Languages\")]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, accommodation, '//img[@alt=\"Accommodation\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, what_else, '//img[@alt=\"What else ...\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, limited_internet, '//*[text()=\"Limited internet access\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, pets, '//*[text()=\"We have pets\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, smokers, '//*[text()=\"We are smokers\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, hosting_families, '//*[text()=\"Can host families\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, digital_nomad, '//*[text()=\"Can host digital nomads\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, campervans, '//*[text()=\"Space for parking camper vans\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, possibly_pets, '//*[text()=\"Can possibly accept pets\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, workawayer_total, '//*[text()=\"How many Workawayers can stay?\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, hours_expected, '//*[text()=\"Hours expected\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, number_of_photos, '//div[contains(@id, \"pic\")]', attribute_version = 0)\n",
    "        extract_element(driver, 1, feedback_accuracy, '(//*[text()=\"These are extra optional ratings when members leave feedback. The average rating left for each option is displayed.\"]//following::p)[1]', 'text')\n",
    "        extract_element(driver, 1, feedback_cultural_exchange, '(//*[text()=\"These are extra optional ratings when members leave feedback. The average rating left for each option is displayed.\"]//following::p)[2]', 'text')\n",
    "        extract_element(driver, 1, feedback_communication, '(//*[text()=\"These are extra optional ratings when members leave feedback. The average rating left for each option is displayed.\"]//following::p)[3]', 'text')\n",
    "        extract_element(driver, 1, ww_comm, '//div[@class=\"feedback_content feedback_content_ww\"]/parent::div/following-sibling::div[@class=\"feedback-thumb-wrapper\"]/span', 'text', attribute_version = 3)\n",
    "        extract_element(driver, 1, h_comm, '//div[@class=\"feedback_content feedback_content_h\"]/parent::div/following-sibling::div[@class=\"feedback-thumb-wrapper\"]/span', 'text', attribute_version = 3)\n",
    "\n",
    "        ### Go to NEXT host\n",
    "        try:\n",
    "            next_host = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//a[@title=\"Next in search result\" or contains(@title, \"Next listing\")]')))\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: END OF HOST LIST\")\n",
    "            break\n",
    "        next_host.click()\n",
    "        i += 1\n",
    "\n",
    "    print(f\"Total number of hosts webscraped in {country} = {i-1}\")\n",
    "    ### Creating DF and exporting to ';' delimited CSV file\n",
    "    df = pd.DataFrame({'title': title,\n",
    "        'country_host': country_host,\n",
    "        'host_rating': host_rating,\n",
    "        'ww_comm': ww_comm,\n",
    "        'h_comm': h_comm,\n",
    "        'feedback_no': feedback_no,\n",
    "        'last_activity': last_activity,\n",
    "        'reply_rate': reply_rate,\n",
    "        'average_reply_time': average_reply_time,\n",
    "        'favourited': favourited,\n",
    "        'min_stay': min_stay,\n",
    "        'description': description,\n",
    "        'types_of_help': types_of_help,\n",
    "        'cultural_exchange': cultural_exchange,\n",
    "        'help': help,\n",
    "        'languages_spoken': languages_spoken,\n",
    "        'accomodation': accommodation,\n",
    "        'what_else': what_else,\n",
    "        'internet_access': internet_access,\n",
    "        'limited_internet': limited_internet,\n",
    "        'pets': pets, \n",
    "        'smokers': smokers,\n",
    "        'hosting_families': hosting_families,\n",
    "        'digital_nomad': digital_nomad,  \n",
    "        'campervans':  campervans,\n",
    "        'possibly_pets': possibly_pets,\n",
    "        'workawayer_total': workawayer_total,\n",
    "        'hours_expected': hours_expected,\n",
    "        'number_of_photos': number_of_photos,\n",
    "        'feedback_accuracy': feedback_accuracy,\n",
    "        'feedback_cultural_exchange': feedback_cultural_exchange,\n",
    "        'feedback_communication': feedback_communication})\n",
    "    saving_path = f'workaway_scraping_{country}.csv'\n",
    "    df.to_csv(saving_path, sep =';', index = False)\n",
    "    driver.close()\n",
    "    driver.switch_to.window(p)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaway script - single country webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workaway_single_country.py\n",
    "from pickle import FALSE\n",
    "import time\n",
    "from operator import contains\n",
    "from select import select\n",
    "from tomlkit import key_value\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##### INPUT AREA #####\n",
    "country = \"Poland\" # What country are you webscraping?\n",
    "website = 'https://www.workaway.info/en/hostlist'\n",
    "feedback = 1\n",
    "lastminute = 0\n",
    "##### END OF INPUT AREA #####\n",
    "\n",
    "def configure_driver():\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    ### Maximize window\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    ### Add the argument and make the browser Headless.\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    ### Instantiate the Webdriver\n",
    "    driver = webdriver.Chrome(options = chrome_options)\n",
    "    return driver\n",
    "\n",
    "### Extracting function on hostlist page\n",
    "def extract_element(driver, \n",
    "                    my_timer, \n",
    "                    element, \n",
    "                    path, \n",
    "                    extract_attribute = 'text', \n",
    "                    attribute_version = 1, \n",
    "                    attribute_value = \"src\"):\n",
    "    if attribute_version == 0:\n",
    "        try:\n",
    "            match_temp = WebDriverWait(driver, my_timer).until(EC.presence_of_all_elements_located((By.XPATH, path)))\n",
    "            match = len(match_temp)\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: photos not found\")\n",
    "            match = np.nan\n",
    "    elif attribute_version == 3:\n",
    "        match = []\n",
    "        try:\n",
    "            match_temp = WebDriverWait(driver, my_timer).until(EC.presence_of_all_elements_located((By.XPATH, path)))\n",
    "            for match_i in match_temp:\n",
    "                match.append(getattr(match_i, extract_attribute))\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: comments not found\")\n",
    "            match = np.nan\n",
    "    else:\n",
    "        try:\n",
    "            match_temp = WebDriverWait(driver, my_timer).until(EC.presence_of_element_located((By.XPATH, path)))\n",
    "            if attribute_version == 2:\n",
    "                try:\n",
    "                    match = getattr(match_temp, extract_attribute)(attribute_value)\n",
    "                except:\n",
    "                    print(\"New error '2' to handle\")\n",
    "            elif attribute_version == 1:\n",
    "                try:\n",
    "                    match = getattr(match_temp, extract_attribute)\n",
    "                except:\n",
    "                    print(\"New error '1' to handle\")\n",
    "        except TimeoutException:\n",
    "            match = np.nan\n",
    "    element.append(match)\n",
    "    #print(element)\n",
    "\n",
    "### Open the Workaway finding host website\n",
    "driver = configure_driver()\n",
    "driver.get(website)\n",
    "\n",
    "### COOKIES ACCEPT\n",
    "cookie_accept = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'CybotCookiebotDialogBodyButtonAccept')))\n",
    "driver.execute_script(\"arguments[0].click();\", cookie_accept)\n",
    "\n",
    "### Check \"only with feedback\" checkbox\n",
    "if feedback == 1 and (driver.find_element(By.ID, 'with_feedback').is_selected()) != True:\n",
    "    driver.find_element(By.ID, 'with_feedback').is_selected()\n",
    "    feedback_checkbox = driver.find_element('xpath', '//label[@for=\"with_feedback\"]/descendant::div')\n",
    "    feedback_checkbox.click()\n",
    "\n",
    "\n",
    "### LOOP THROUUGH COUNTRIES IN THE CSV LIST\n",
    "try:\n",
    "    searchbar = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//input[@placeholder=\"Anywhere\"]')))\n",
    "except TimeoutException:\n",
    "    print(f'INFO: Looks like you broken the site during {country} search')\n",
    "    driver.quit()\n",
    "    driver.get(website)\n",
    "\n",
    "searchbar.click()\n",
    "time.sleep(2)\n",
    "print(f'printing just before sending the command to searchbox {country}')\n",
    "searchbar.clear()\n",
    "searchbar.send_keys(country) \n",
    "time.sleep(2)\n",
    "searchbar.send_keys(Keys.ARROW_DOWN)\n",
    "searchbar.send_keys(Keys.ENTER)\n",
    "### Handling of optional visa popup - United Kingdom and United States\n",
    "try:\n",
    "    visabutton = WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.XPATH, '//button[@data-action=\"visaagree\"]')))\n",
    "    visabutton.click()\n",
    "except TimeoutException:\n",
    "    print(\"No Visa popup to handle\")    ### Find first host on the Listentry Title object and open it\n",
    "\n",
    "### Lists initialization\n",
    "title = [] #\n",
    "country_host = [] #\n",
    "host_rating = [] #\n",
    "feedback_no = [] #\n",
    "h_comm = [] #\n",
    "ww_comm = [] #\n",
    "last_activity = [] #\n",
    "reply_rate = [] #\n",
    "average_reply_time = [] #\n",
    "favourited = [] #\n",
    "min_stay = [] #\n",
    "description = [] #\n",
    "types_of_help = [] #\n",
    "cultural_exchange = [] #\n",
    "help = [] #\n",
    "languages_spoken = [] #\n",
    "accommodation = [] #\n",
    "what_else = [] #\n",
    "internet_access = [] #\n",
    "limited_internet = [] #\n",
    "pets = [] #\n",
    "smokers = [] #\n",
    "hosting_families = [] #\n",
    "digital_nomad = [] #\n",
    "campervans = [] #\n",
    "possibly_pets = [] #\n",
    "workawayer_total = [] #\n",
    "hours_expected = [] #\n",
    "number_of_photos = [] #\n",
    "feedback_accuracy = [] #\n",
    "feedback_cultural_exchange = [] #\n",
    "feedback_communication = [] #\n",
    "\n",
    "### WEBSCRAPING THE HOST DATA ###\n",
    "### LOOP to iterate over consecutive pages \n",
    "j = 1\n",
    "while j < 400:  \n",
    "    ### Find first host on the Listentry Title object and open it\n",
    "    i = 1\n",
    "    ### LOOP for iterating over Listentry object which contains always 20hosts / 1 page\n",
    "    while i < 21:\n",
    "        path_combined = f'(//div[@class=\"listentry-content\"]/child::a)[{i}]'\n",
    "        try:\n",
    "            hostlist = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, path_combined)))\n",
    "        except TimeoutException:\n",
    "            print(\"TimeoutException: END OF HOST LIST\")\n",
    "            break\n",
    "        driver.execute_script(\"arguments[0].click();\", hostlist)\n",
    "        ### Handling opened tabs\n",
    "        p = driver.window_handles[0]\n",
    "        #obtain browser tab window\n",
    "        c = driver.window_handles[1]\n",
    "        driver.switch_to.window(c)\n",
    "        extract_element(driver, 10, title, '//div[@class=\"details\"]//child::h1', 'text')\n",
    "        extract_element(driver, 1, country_host, '//div[@class=\"country-row\"]//child::p', 'text')\n",
    "        extract_element(driver, 1, host_rating, '//div[contains(@class, \"hr\")]', 'get_attribute', attribute_version = 2, attribute_value = \"class\")\n",
    "        extract_element(driver, 1, feedback_no, '//h2[text()=\"Feedback\"]//parent::div//following-sibling::div[1]//p', 'text')\n",
    "        extract_element(driver, 1, last_activity, '//*[text()=\"Last activity\"]//following::div[1]//child::p', 'text')\n",
    "        extract_element(driver, 1, reply_rate, '//*[text()=\"Reply rate\"]//following::div[1]//child::p', 'text')\n",
    "        extract_element(driver, 1, average_reply_time, '//*[text()=\"Average reply time:\"]//following::div[1]//child::p', 'text')\n",
    "        extract_element(driver, 1, favourited, '//p[@class=\"blue-text\"]', 'text')\n",
    "        extract_element(driver, 1, min_stay, '//p[@class=\"text-muted\"]', 'text')\n",
    "        extract_element(driver, 1, description, '(//div[@id=\"section-information\"]//descendant::p)[1]', 'text')\n",
    "        extract_element(driver, 1, types_of_help, '(//div[@id=\"section-information\"]//descendant::p)[2]', 'text')\n",
    "        extract_element(driver, 1, internet_access, '//*[text()=\"Internet access\"]//parent::div//parent::li//img[contains(@src, \"\")]', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, cultural_exchange, '//img[@alt=\"Cultural exchange and learning opportunities\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, help, '//img[@alt=\"Help\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, languages_spoken, '//h2[contains(text(), \"Languages\")]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, accommodation, '//img[@alt=\"Accommodation\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, what_else, '//img[@alt=\"What else ...\"]//parent::li//child::p', 'text')\n",
    "        extract_element(driver, 1, limited_internet, '//*[text()=\"Limited internet access\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, pets, '//*[text()=\"We have pets\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, smokers, '//*[text()=\"We are smokers\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, hosting_families, '//*[text()=\"Can host families\"]//parent::div//parent::li//child::img', 'get_attribute', attribute_version = 2, attribute_value = \"src\")\n",
    "        extract_element(driver, 1, digital_nomad, '//*[text()=\"Can host digital nomads\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, campervans, '//*[text()=\"Space for parking camper vans\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, possibly_pets, '//*[text()=\"Can possibly accept pets\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, workawayer_total, '//*[text()=\"How many Workawayers can stay?\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, hours_expected, '//*[text()=\"Hours expected\"]//parent::div//child::p', 'text')\n",
    "        extract_element(driver, 1, number_of_photos, '//div[contains(@id, \"pic\")]', attribute_version = 0)\n",
    "        extract_element(driver, 1, feedback_accuracy, '(//*[text()=\"These are extra optional ratings when members leave feedback. The average rating left for each option is displayed.\"]//following::p)[1]', 'text')\n",
    "        extract_element(driver, 1, feedback_cultural_exchange, '(//*[text()=\"These are extra optional ratings when members leave feedback. The average rating left for each option is displayed.\"]//following::p)[2]', 'text')\n",
    "        extract_element(driver, 1, feedback_communication, '(//*[text()=\"These are extra optional ratings when members leave feedback. The average rating left for each option is displayed.\"]//following::p)[3]', 'text')\n",
    "        extract_element(driver, 1, ww_comm, '//div[@class=\"feedback_content feedback_content_ww\"]/parent::div/following-sibling::div[@class=\"feedback-thumb-wrapper\"]/span', 'text', attribute_version = 3)\n",
    "        extract_element(driver, 1, h_comm, '//div[@class=\"feedback_content feedback_content_h\"]/parent::div/following-sibling::div[@class=\"feedback-thumb-wrapper\"]/span', 'text', attribute_version = 3)\n",
    "        driver.close()\n",
    "        driver.switch_to.window(p)\n",
    "        i += 1\n",
    "    try:\n",
    "        next_page = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//li[@class=\"pagination-custom-next\"]//a')))\n",
    "    except:\n",
    "        print(\"Next button not found\")\n",
    "        break\n",
    "    next_page.click()\n",
    "    j += 1\n",
    "\n",
    "print(f\"Total number of hosts webscraped in {country} = {i*j}\")\n",
    "\n",
    "### Creating DF and exporting to ';' delimited CSV file\n",
    "df = pd.DataFrame({'title': title,\n",
    "    'country_host': country_host,\n",
    "    'host_rating': host_rating,\n",
    "    'ww_comm': ww_comm,\n",
    "    'h_comm': h_comm,\n",
    "    'feedback_no': feedback_no,\n",
    "    'last_activity': last_activity,\n",
    "    'reply_rate': reply_rate,\n",
    "    'average_reply_time': average_reply_time,\n",
    "    'favourited': favourited,\n",
    "    'min_stay': min_stay,\n",
    "    'description': description,\n",
    "    'types_of_help': types_of_help,\n",
    "    'cultural_exchange': cultural_exchange,\n",
    "    'help': help,\n",
    "    'languages_spoken': languages_spoken,\n",
    "    'accomodation': accommodation,\n",
    "    'what_else': what_else,\n",
    "    'internet_access': internet_access,\n",
    "    'limited_internet': limited_internet,\n",
    "    'pets': pets, \n",
    "    'smokers': smokers,\n",
    "    'hosting_families': hosting_families,\n",
    "    'digital_nomad': digital_nomad,  \n",
    "    'campervans':  campervans,\n",
    "    'possibly_pets': possibly_pets,\n",
    "    'workawayer_total': workawayer_total,\n",
    "    'hours_expected': hours_expected,\n",
    "    'number_of_photos': number_of_photos,\n",
    "    'feedback_accuracy': feedback_accuracy,\n",
    "    'feedback_cultural_exchange': feedback_cultural_exchange,\n",
    "    'feedback_communication': feedback_communication})\n",
    "saving_path = f'workaway_scraping_{country}.csv'\n",
    "df.to_csv(saving_path, sep =';', index = False)\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('workaway_webscraping_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74432ea5277d3d903fd9859de89bf6933950ca1697c5c01d6191d2d15624c7a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
